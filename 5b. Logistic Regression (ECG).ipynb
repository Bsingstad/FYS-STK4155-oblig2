{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%reload_ext autoreload\n",
    "from Scripts import get_data\n",
    "from Scripts import NeuralNetwork\n",
    "from Scripts import plot\n",
    "from Scripts import metrics\n",
    "from Scripts import ECG_processing\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import random\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./Data/train_data_ptb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./Data/test_data_ptb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1021, 1021, 1021, 1021, 1021, 1021, 1021, 1021, 1021, 1021, 1021,\n",
      "       1021, 1021, 1021, 1021, 1021, 1021, 1021, 1021, 1021, 1021, 1597,\n",
      "       1597, 1597, 1597, 1597, 1597, 1597, 1597, 1597, 2030, 2030, 2030,\n",
      "       2030, 2030, 2030, 2030, 2030, 2030], dtype=int64), array([ 86,  87,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,\n",
      "       101, 102, 103, 104, 107, 108, 109, 112,  86,  87,  90, 103, 104,\n",
      "       107, 108, 109, 112,  86,  87,  90, 103, 104, 107, 108, 109, 112],\n",
      "      dtype=int64))\n",
      "Int64Index([], dtype='int64')\n",
      "-------\n",
      "0\n",
      "1021\n",
      "86\n",
      "nan\n",
      "1\n",
      "-------\n",
      "1\n",
      "1021\n",
      "90\n",
      "nan\n",
      "2\n",
      "-------\n",
      "2\n",
      "1021\n",
      "92\n",
      "nan\n",
      "3\n",
      "-------\n",
      "3\n",
      "1021\n",
      "94\n",
      "nan\n",
      "4\n",
      "-------\n",
      "4\n",
      "1021\n",
      "96\n",
      "nan\n",
      "5\n",
      "-------\n",
      "5\n",
      "1021\n",
      "98\n",
      "nan\n",
      "6\n",
      "-------\n",
      "6\n",
      "1021\n",
      "100\n",
      "nan\n",
      "7\n",
      "-------\n",
      "7\n",
      "1021\n",
      "102\n",
      "nan\n",
      "8\n",
      "-------\n",
      "8\n",
      "1021\n",
      "104\n",
      "nan\n",
      "9\n",
      "-------\n",
      "9\n",
      "1021\n",
      "108\n",
      "nan\n",
      "10\n",
      "-------\n",
      "10\n",
      "1021\n",
      "112\n",
      "nan\n",
      "11\n",
      "-------\n",
      "11\n",
      "1021\n",
      "87\n",
      "nan\n",
      "12\n",
      "-------\n",
      "12\n",
      "1021\n",
      "103\n",
      "nan\n",
      "13\n",
      "-------\n",
      "13\n",
      "1021\n",
      "107\n",
      "nan\n",
      "14\n",
      "-------\n",
      "14\n",
      "1021\n",
      "109\n",
      "nan\n",
      "15\n",
      "-------\n",
      "15\n",
      "1021\n",
      "86\n",
      "14.939227040749353\n",
      "16\n",
      "-------\n",
      "16\n",
      "1021\n",
      "87\n",
      "75.01747710530589\n",
      "17\n",
      "-------\n",
      "17\n",
      "1021\n",
      "90\n",
      "78.94823922112606\n",
      "18\n",
      "-------\n",
      "18\n",
      "1021\n",
      "103\n",
      "15.988065782919795\n",
      "19\n",
      "-------\n",
      "19\n",
      "1021\n",
      "104\n",
      "75.08083513696856\n",
      "20\n",
      "-------\n",
      "20\n",
      "1021\n",
      "107\n",
      "79.26914674133708\n",
      "21\n",
      "-------\n",
      "21\n",
      "1597\n",
      "108\n",
      "nan\n",
      "22\n",
      "-------\n",
      "22\n",
      "1597\n",
      "112\n",
      "nan\n",
      "23\n",
      "-------\n",
      "23\n",
      "1597\n",
      "-------\n",
      "0\n",
      "1021\n",
      "91\n",
      "nan\n",
      "24\n",
      "-------\n",
      "1\n",
      "1021\n",
      "95\n",
      "nan\n",
      "25\n",
      "-------\n",
      "2\n",
      "1021\n",
      "99\n",
      "nan\n",
      "26\n",
      "-------\n",
      "3\n",
      "1021\n",
      "86\n",
      "14.939227040749355\n",
      "27\n",
      "-------\n",
      "4\n",
      "1021\n",
      "87\n",
      "75.01747710530589\n",
      "28\n",
      "-------\n",
      "5\n",
      "1021\n",
      "90\n",
      "78.94823922112606\n",
      "29\n",
      "-------\n",
      "6\n",
      "1597\n",
      "103\n",
      "nan\n",
      "30\n",
      "-------\n",
      "7\n",
      "1597\n",
      "107\n",
      "nan\n",
      "31\n",
      "-------\n",
      "8\n",
      "1597\n",
      "86\n",
      "nan\n",
      "32\n",
      "-------\n",
      "9\n",
      "1597\n",
      "90\n",
      "nan\n",
      "33\n",
      "-------\n",
      "10\n",
      "1597\n",
      "104\n",
      "nan\n",
      "34\n",
      "-------\n",
      "11\n",
      "1597\n",
      "108\n",
      "16.928863236802357\n",
      "35\n",
      "-------\n",
      "12\n",
      "1597\n",
      "109\n",
      "nan\n",
      "36\n",
      "-------\n",
      "13\n",
      "2030\n",
      "-------\n",
      "0\n",
      "1021\n",
      "93\n",
      "nan\n",
      "37\n",
      "-------\n",
      "1\n",
      "1021\n",
      "101\n",
      "nan\n",
      "38\n",
      "-------\n",
      "2\n",
      "1021\n",
      "86\n",
      "14.939227040749355\n",
      "39\n",
      "-------\n",
      "3\n",
      "1597\n",
      "87\n",
      "nan\n",
      "40\n",
      "-------\n",
      "4\n",
      "2030\n",
      "103\n",
      "nan\n",
      "41\n",
      "-------\n",
      "5\n",
      "2030\n",
      "107\n",
      "nan\n",
      "42\n",
      "-------\n",
      "6\n",
      "2030\n",
      "109\n",
      "nan\n",
      "43\n",
      "-------\n",
      "7\n",
      "2030\n",
      "-------\n",
      "0\n",
      "1021\n",
      "97\n",
      "nan\n",
      "44\n",
      "-------\n",
      "1\n",
      "2030\n",
      "87\n",
      "nan\n",
      "45\n",
      "-------\n",
      "2\n",
      "2030\n",
      "104\n",
      "nan\n",
      "46\n",
      "-------\n",
      "3\n",
      "2030\n",
      "112\n",
      "nan\n",
      "47\n",
      "-------\n",
      "4\n",
      "2030\n",
      "-------\n",
      "0\n",
      "2030\n",
      "86\n",
      "nan\n",
      "48\n",
      "-------\n",
      "1\n",
      "2030\n",
      "108\n",
      "nan\n",
      "49\n",
      "-------\n",
      "2\n",
      "2030\n",
      "-------\n",
      "0\n",
      "2030\n",
      "90\n",
      "nan\n",
      "50\n",
      "(array([  281,   281,   281,   281,   281,   281,   281,   281,   281,\n",
      "         281,   281,   281,   281,   281,   281,   281,   281,   281,\n",
      "         281,   281,   281,   477,   477,   477,   477,   477,   477,\n",
      "         477,   477,   477,   477,   477,   477,   477,   477,   477,\n",
      "         477,   477,   477,   477,   477,   477,  3294,  3294,  3294,\n",
      "        3294,  3294,  3294,  3294,  3294,  3294,  3294,  3294,  3294,\n",
      "        3294,  3294,  3294,  3294,  3294,  3294,  3294,  3294,  3294,\n",
      "        3298,  3298,  3298,  3298,  3298,  3298,  3298,  3298,  3298,\n",
      "        3299,  3299,  3299,  3299,  3299,  3299,  3299,  3299,  3299,\n",
      "        3546,  3546,  3546,  3546,  3546,  3546,  3546,  3546,  3546,\n",
      "        3546,  3546,  3546,  3546,  3546,  3546,  3546,  3546,  3546,\n",
      "        3546,  3546,  3546,  4141,  4141,  4141,  4141,  4141,  4141,\n",
      "        4141,  4141,  4141,  5882,  5882,  5882,  5882,  5882,  5882,\n",
      "        5882,  5882,  5882,  5882,  5882,  5882,  5882,  5882,  5882,\n",
      "        5882,  5882,  5882,  5882,  5882,  5882,  5907,  5907,  5907,\n",
      "        6061,  6061,  6061,  6061,  6061,  6061,  6061,  6061,  6061,\n",
      "        6086,  6086,  6086,  6086,  6086,  6086,  6086,  6086,  6086,\n",
      "        6086,  6086,  6086,  6086,  6086,  6086,  6086,  6086,  6086,\n",
      "        6086,  6086,  6086,  6374,  6374,  6374,  6374,  6374,  6374,\n",
      "        6374,  6374,  6374,  6374,  6374,  6374,  6374,  6374,  6374,\n",
      "        6374,  6374,  6374,  6374,  6374,  6374,  6571,  6571,  6571,\n",
      "        6571,  6571,  6571,  6571,  6571,  6571,  6571,  6571,  6571,\n",
      "        6571,  6571,  6571,  6571,  6571,  6571,  6571,  6571,  6571,\n",
      "        6614,  6614,  6614,  6619,  6619,  6619,  6619,  6619,  6619,\n",
      "        6619,  6619,  6619,  6619,  6619,  6619,  6619,  6619,  6619,\n",
      "        6619,  6619,  6619,  6619,  6619,  6619,  6983,  6983,  6983,\n",
      "        6983,  6983,  6983,  6983,  6983,  6983,  7449,  7449,  7449,\n",
      "        7449,  7449,  7449,  7449,  7449,  7449,  7449,  7449,  7449,\n",
      "        7449,  7449,  7449,  7449,  7449,  7449,  7449,  7449,  7449,\n",
      "        7918,  7918,  7918,  7918,  7918,  7918,  7918,  7918,  7918,\n",
      "        7930,  7930,  7930,  7930,  7930,  7930,  7930,  7930,  7930,\n",
      "        7930,  7930,  7930,  7930,  7930,  7930,  7930,  7930,  7930,\n",
      "        7930,  7930,  7930,  7948,  7948,  7948,  7948,  7948,  7948,\n",
      "        7948,  7948,  7948,  9056,  9056,  9056,  9056,  9056,  9056,\n",
      "        9056,  9056,  9056,  9133,  9133,  9133,  9133,  9133,  9133,\n",
      "        9133,  9133,  9133,  9133,  9133,  9133,  9133,  9133,  9133,\n",
      "        9133,  9133,  9133,  9133,  9133,  9133,  9419,  9419,  9419,\n",
      "        9419,  9419,  9419,  9419,  9419,  9419, 10924, 11111, 11111,\n",
      "       11111, 11111, 11111, 11111, 11111, 11111, 11111, 11111, 11111,\n",
      "       11111, 11111, 11111, 11111, 11111, 11111, 11111, 11111, 11111,\n",
      "       11111, 11473, 11473, 11473, 11473, 11473, 11473, 11473, 11473,\n",
      "       11473, 13636, 13636, 13636, 13925, 13925, 13925, 13925, 13925,\n",
      "       13925, 13925, 13925, 13925, 13925, 13925, 13925, 13925, 13925,\n",
      "       13925, 13925, 13925, 13925, 13925, 13925, 13925, 14354, 14354,\n",
      "       14354, 14354, 14354, 14354, 14354, 14354, 14354, 14354, 14354,\n",
      "       14354, 14354, 14354, 14354, 14354, 14354, 14354, 14354, 14354,\n",
      "       14354, 14463, 14463, 14463, 14463, 14463, 14463, 14463, 14463,\n",
      "       14463, 14532, 14532, 14532, 14532, 14532, 14532, 14532, 14532,\n",
      "       14532, 14654, 14654, 14654, 14654, 14654, 14654, 14654, 14654,\n",
      "       14654, 14654, 14654, 14654, 14654, 14654, 14654, 14654, 14654,\n",
      "       14654, 14654, 14654, 14654, 15773, 15773, 15773, 15773, 15773,\n",
      "       15773, 15773, 15773, 15773, 15773, 15773, 15773, 15773, 15773,\n",
      "       15773, 15773, 15773, 15773, 15773, 15773, 15773, 15945, 15945,\n",
      "       15945, 16463, 16463, 16463, 16463, 16463, 16463, 16463, 16463,\n",
      "       16463, 16463, 16463, 16463, 16463, 16463, 16463, 16463, 16463,\n",
      "       16463, 16463, 16463, 16463, 17300, 17378, 17378, 17378, 17378,\n",
      "       17378, 17378, 17378, 17378, 17378, 17378, 17378, 17378, 17378,\n",
      "       17378, 17378, 17378, 17378, 17378, 17378, 17378, 17378, 17384,\n",
      "       17384, 17384, 17384, 17384, 17384, 17384, 17384, 17384, 18000,\n",
      "       18000, 18000, 18355, 18355, 18355, 18355, 18355, 18355, 18355,\n",
      "       18355, 18355, 18355, 18355, 18355, 18355, 18355, 18355, 18355,\n",
      "       18355, 18355, 18355, 18355, 18355, 18692, 18804, 18804, 18804,\n",
      "       18804, 18804, 18804, 18804, 18804, 18804, 18935, 18935, 18935,\n",
      "       19360, 19360, 19360, 19360, 19360, 19360, 19360, 19360, 19360,\n",
      "       19360, 19360, 19360, 19360, 19360, 19360, 19360, 19360, 19360,\n",
      "       19360, 19360, 19360], dtype=int64), array([ 86,  87,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,\n",
      "       101, 102, 103, 104, 107, 108, 109, 112,  86,  87,  90,  91,  92,\n",
      "        93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 107,\n",
      "       108, 109, 112,  86,  87,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "        98,  99, 100, 101, 102, 103, 104, 107, 108, 109, 112,  86,  87,\n",
      "        90, 103, 104, 107, 108, 109, 112,  86,  87,  90, 103, 104, 107,\n",
      "       108, 109, 112,  86,  87,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "        98,  99, 100, 101, 102, 103, 104, 107, 108, 109, 112,  86,  87,\n",
      "        90, 103, 104, 107, 108, 109, 112,  86,  87,  90,  91,  92,  93,\n",
      "        94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 107, 108,\n",
      "       109, 112,  86, 103, 108,  86,  87,  90, 103, 104, 107, 108, 109,\n",
      "       112,  86,  87,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n",
      "       100, 101, 102, 103, 104, 107, 108, 109, 112,  86,  87,  90,  91,\n",
      "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "       107, 108, 109, 112,  86,  87,  90,  91,  92,  93,  94,  95,  96,\n",
      "        97,  98,  99, 100, 101, 102, 103, 104, 107, 108, 109, 112,  86,\n",
      "       103, 108,  86,  87,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "        99, 100, 101, 102, 103, 104, 107, 108, 109, 112,  86,  87,  90,\n",
      "       103, 104, 107, 108, 109, 112,  86,  87,  90,  91,  92,  93,  94,\n",
      "        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 107, 108, 109,\n",
      "       112,  86,  87,  90, 103, 104, 107, 108, 109, 112,  86,  87,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 107, 108, 109, 112,  86,  87,  90, 103, 104, 107, 108, 109,\n",
      "       112,  86,  87,  90, 103, 104, 107, 108, 109, 112,  86,  87,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 107, 108, 109, 112,  86,  87,  90, 103, 104, 107, 108, 109,\n",
      "       112,  69,  86,  87,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "        99, 100, 101, 102, 103, 104, 107, 108, 109, 112,  86,  87,  90,\n",
      "       103, 104, 107, 108, 109, 112,  86, 103, 108,  86,  87,  90,  91,\n",
      "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "       107, 108, 109, 112,  86,  87,  90,  91,  92,  93,  94,  95,  96,\n",
      "        97,  98,  99, 100, 101, 102, 103, 104, 107, 108, 109, 112,  86,\n",
      "        87,  90, 103, 104, 107, 108, 109, 112,  86,  87,  90, 103, 104,\n",
      "       107, 108, 109, 112,  86,  87,  90,  91,  92,  93,  94,  95,  96,\n",
      "        97,  98,  99, 100, 101, 102, 103, 104, 107, 108, 109, 112,  86,\n",
      "        87,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
      "       102, 103, 104, 107, 108, 109, 112,  86, 103, 108,  86,  87,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 107, 108, 109, 112,  69,  86,  87,  90,  91,  92,  93,  94,\n",
      "        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 107, 108, 109,\n",
      "       112,  86,  87,  90, 103, 104, 107, 108, 109, 112,  86, 103, 108,\n",
      "        86,  87,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,\n",
      "       101, 102, 103, 104, 107, 108, 109, 112,  69,  86,  87,  90, 103,\n",
      "       104, 107, 108, 109, 112,  86, 103, 108,  86,  87,  90,  91,  92,\n",
      "        93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 107,\n",
      "       108, 109, 112], dtype=int64))\n",
      "Int64Index([5907, 6614, 10924, 13636, 15945, 17300, 18000, 18692, 18935], dtype='int64')\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "Int64Index([], dtype='int64')\n",
      "(19564, 114)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "print(np.where(test_data.iloc[:,:-1].isna()))\n",
    "print(test_data.index[np.isinf(test_data.iloc[:,:-1]).any(1)])\n",
    "#print(test_data.columns.to_series()[np.isinf(test_data.iloc[:,:-1]).any()])\n",
    "\n",
    "count = 0\n",
    "while len(np.where(test_data.iloc[:,:-1].isna())[1]) != 0:\n",
    "    try:\n",
    "        for i,j in enumerate(np.where(test_data.iloc[:,:-1].isna())[0]):\n",
    "            print(\"-------\")\n",
    "            print(i)\n",
    "            print(j)\n",
    "            print(np.where(test_data.iloc[:,:-1].isna())[1][i])\n",
    "            print(test_data.iloc[j,np.where(test_data.iloc[:,:-1].isna())[1][i]])\n",
    "            test_data.iloc[j,np.where(test_data.iloc[:,:-1].isna())[1][i]] = test_data.iloc[:,np.where(test_data.iloc[:,:-1].isna())[1][i]].mean()\n",
    "            count = count + 1\n",
    "            print(count)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "print(np.where(train_data.iloc[:,:-1].isna()))\n",
    "print(train_data.index[np.isinf(train_data.iloc[:,:-1]).any(1)])\n",
    "#print(data.columns.to_series()[np.isinf(data.iloc[:,:-1]).any()])\n",
    "\n",
    "train_data = train_data.dropna()\n",
    "\n",
    "print(np.where(train_data.iloc[:,1:-1].isna()))\n",
    "print(train_data.index[np.isinf(train_data.iloc[:,1:-1]).any(1)])\n",
    "#print(data.columns.to_series()[np.isinf(data.iloc[:,1:-1]).any()])\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['Labels'].str.lstrip(\"'[\").str.rstrip(\"]'\").str.replace(\"'\", \"\").str.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_data['Labels'].str.lstrip(\"'[\").str.rstrip(\"]'\").str.replace(\"'\", \"\").str.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.iloc[:,1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.iloc[:,1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['' 'CD' 'HYP' 'MI' 'NORM' 'STTC']\n",
      "classes: 6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "one_hot = MultiLabelBinarizer()\n",
    "y_train_ohe=one_hot.fit_transform(y_train.str.split(','))\n",
    "print(one_hot.classes_)\n",
    "print(\"classes: {}\".format(y_train_ohe.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CD', 'HYP', 'MI', 'NORM', 'STTC'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot.classes_[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ohe=y_train_ohe[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique combinations of diagnosis: 22\n"
     ]
    }
   ],
   "source": [
    " = ECG_processing.get_new_labels(y_train_ohe)\n",
    "print(\"Total number of unique combinations of diagnosis: {}\".format(len(np.unique(y_train_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique combinations of diagnosis: 22\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y_train_ = encoder.fit_transform([''.join(str(l)) for l in y_train_ohe])\n",
    "print(\"Total number of unique combinations of diagnosis: {}\".format(len(np.unique(y_train_))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SKlearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    8.4s finished\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(LogisticRegression(random_state=42, verbose=1, n_jobs=-1)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NORM', 'NORM', 'NORM', ..., 'NORM', 'NORM', 'NORM'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4148887880163413\n",
      "F1-score: 0.029879391589213287\n",
      "F2-score: 0.03935493185493186\n",
      "F0.5-score: 0.024768804739824835\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"F2-score:\", fbeta_score(y_test, y_pred_test, average='macro', beta=2))\n",
    "print(\"F0.5-score:\", fbeta_score(y_test, y_pred_test, average='macro', beta=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NORM', 'NORM', 'NORM', ..., 'NORM', 'NORM', 'NORM'], dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = plot.compute_modified_confusion_matrix_nonorm(y_test_ohe, y_pred_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a60efb73604c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#for label size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"rocket_r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mannot_kws\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"size\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\".2f\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predict MNIST data using SKlearn Logistic Regression\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"black\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y predicted\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"black\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize = (20,20))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(conf_matrix, cmap=\"rocket_r\", annot=True,annot_kws={\"size\": 20}, fmt=\".2f\", cbar=False)\n",
    "plt.title(\"Predict MNIST data using SKlearn Logistic Regression\", fontsize = 40, color= \"black\")\n",
    "plt.xlabel(\"y predicted\",fontsize=30, color= \"black\")\n",
    "plt.ylabel(\"y true\",fontsize = 30, color= \"black\")\n",
    "plt.yticks(fontsize=30, rotation=0, color= \"black\")\n",
    "plt.xticks(fontsize=30, rotation=0, color= \"black\")\n",
    "plt.savefig(\"Results/MNIST_confMatrix_sklearn_logreg.png\",dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using own algorithm:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
